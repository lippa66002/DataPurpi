# ğŸµ Popularity & Musical Characteristics of Songs Across Streaming Platforms 

This project investigates how **musical features** (e.g., danceability, energy, valence, tempo) influence **song popularity** across streaming platforms such as Spotify, Apple Music, Deezer, and Shazam.  

We use **Apache Spark** for large-scale processing, **HDFS** for distributed storage, and **MLlib** for predictive modeling and clustering.  
Visualizations and dashboards are built with **Tableau / Plotly / Matplotlib**.  

---

## ğŸ“Œ Objectives
- Identify which audio features most strongly correlate with popularity.
- Analyze differences across **genres** and **time periods**.
- Predict a trackâ€™s popularity from its musical composition.
- Cluster songs into **data-driven groups** (new â€œgenresâ€) based on audio features.
- Explore artist/album dynamics and collaboration effects.

---

## ğŸ› ï¸ Tech Stack
- **Storage**: HDFS (or Parquet for Colab runs)  
- **Processing**: Apache Spark (PySpark, Spark SQL, Spark MLlib)  
- **Machine Learning**: Regression, Classification, Clustering (MLlib)  
- **Visualization**: Tableau, Plotly, Matplotlib, Seaborn  
- **Version Control**: GitHub (+ Issues, Projects, Actions)  
- **Optional**: DVC for dataset versioning, Kafka for streaming simulation  

---

## ğŸ“‚ Repository Structure
```
music-popularity-spark/
â”œâ”€ data/                 # raw & processed data (ignored in Git)
â”œâ”€ notebooks/            # Colab/Jupyter notebooks for EDA & prototyping
â”œâ”€ src/
â”‚  â”œâ”€ ingestion.py       # Load dataset (Kaggle â†’ HDFS/Parquet)
â”‚  â”œâ”€ preprocessing.py   # Cleaning, scaling, encoding
â”‚  â”œâ”€ features.py        # Feature engineering
â”‚  â”œâ”€ modeling.py        # MLlib regression/classification pipelines
â”‚  â”œâ”€ clustering.py      # KMeans & segmentation
â”‚  â”œâ”€ evaluation.py      # Metrics (RMSE, RÂ², Precision/Recall)
â”‚  â””â”€ utils.py           # Helper functions
â”œâ”€ dashboards/           # Tableau/Plotly dashboards
â”œâ”€ conf/                 # Config files (YAML for Spark, thresholds, etc.)
â”œâ”€ tests/                # Unit tests
â”œâ”€ requirements.txt      # Python dependencies
â”œâ”€ environment.yml       # (optional, for conda)
â”œâ”€ dvc.yaml              # (optional, if using DVC for data)
â””â”€ README.md             # Project documentation
```

---

## âš¡ Getting Started

### 1. Clone the repository
```bash
git clone https://github.com/<your-org>/music-popularity-spark.git
cd music-popularity-spark
```

### 2. Dataset (Kaggle)
We use the [Spotify Tracks Dataset](https://www.kaggle.com/datasets/maharshipandya/-spotify-tracks-dataset).  

Download via **Kaggle API**:
```bash
pip install kaggle
kaggle datasets download -d maharshipandya/-spotify-tracks-dataset -p data/
unzip data/*.zip -d data/
```

> âš ï¸ The dataset is large â†’ not committed to Git. Use **DVC** or shared storage.

### 3. Run Spark on Colab (quick start)
In a Colab notebook:
```python
!pip -q install pyspark==3.5.1

from pyspark.sql import SparkSession
spark = (SparkSession.builder
         .appName("music-popularity")
         .master("local[*]")
         .config("spark.sql.shuffle.partitions", "8")
         .getOrCreate())

df = spark.read.csv("data/spotify_tracks.csv", header=True, inferSchema=True)
df.printSchema()
```

### 4. Run with HDFS (optional, advanced)
Using Docker (single-node Hadoop + Spark):
```bash
docker-compose up -d
# put data into HDFS
docker exec -it namenode hdfs dfs -mkdir -p /data/raw
docker exec -it namenode hdfs dfs -put data/spotify_tracks.csv /data/raw/
```
Then in Spark:
```python
df = spark.read.csv("hdfs://namenode:9000/data/raw/spotify_tracks.csv", header=True, inferSchema=True)
```

### 5. Run on Databricks (alternative)
- Import CSV into **DBFS**.  
- Use **Repos** to connect GitHub repo.  
- Run Spark SQL + MLlib pipelines in shared workspace.  

---

## ğŸš€ Project Workflow
1. **Data Ingestion & Cleaning**  
   - Load dataset (CSV â†’ Spark DataFrame).  
   - Handle missing values & outliers.  
   - Normalize numerical features, encode categorical ones.  

2. **Exploratory Data Analysis (EDA)**  
   - Correlations between audio features & popularity.  
   - Temporal analysis (release year, recency).  
   - Genre-level comparisons.  

3. **Modeling (Spark MLlib)**  
   - Regression: predict popularity score.  
   - Classification: predict whether a song enters charts.  
   - Clustering: group songs by musical features.  

4. **Visualization & Insights**  
   - Tableau/Plotly dashboards.  
   - Feature importance plots, cluster profiles, temporal trends.  

---

## ğŸ‘¥ Team Roles
- **Data Lead**: ingestion, DVC, schema management  
- **ML Lead**: regression, classification, feature importance  
- **Platform Lead**: Spark config, Docker/VM/HDFS, CI/CD  
- **Visualization Lead**: dashboards, storytelling, reporting  

---

## âœ… Expected Outcomes
- Key **drivers of popularity** across genres & time.  
- Predictive models for new track popularity.  
- Clusters of songs â†’ new â€œdata-driven genresâ€.  
- Interactive dashboards for artists, producers, and labels.  

---

## ğŸ“Œ References
- Kaggle Dataset: [Spotify Tracks](https://www.kaggle.com/datasets/maharshipandya/-spotify-tracks-dataset)  
- Apache Spark MLlib Docs: https://spark.apache.org/docs/latest/ml-guide.html  
- DVC (Data Version Control): https://dvc.org/  
- Databricks Community: https://community.cloud.databricks.com/  

---
