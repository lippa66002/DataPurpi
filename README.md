ğŸµ From Sound to Insight

Scalable Feature Engineering, Popularity Modeling, and Clustering of Spotify Tracks with Apache Spark

Authors:
Leonardo Liparulo Â· Emanuele Minotti Â· Stefano Romano Â· Giannantonio Sanrocco
ğŸ“§ minotti | sromano | sanrocco | liparulo @kth.se

â¸»

ğŸ“˜ Overview

This project investigates the relationship between musical features and the popularity of Spotify tracks, implementing a fully scalable big data pipeline using Hadoop and Apache Spark.
We designed an end-to-end distributed workflow that handles ingestion, preprocessing, modeling, and clustering over a large dataset to demonstrate the principles of data-intensive computing.

â¸»

ğŸ—‚ï¸ Dataset

We use the Spotify Tracks Dataset (â‰ˆ114,000 songs), containing:
	â€¢	Identifiers & metadata (track ID, name, genre)
	â€¢	Compositional features: tempo, key, mode, duration, time signature
	â€¢	Audio descriptors: danceability, energy, loudness, valence, acousticness, etc.
	â€¢	Target variable: popularity (0â€“100)

â¸»

âš™ï¸ Methodology

1. Data Ingestion
	â€¢	Configured Hadoop 3.3.6 inside Google Colab as a single-node HDFS cluster.
	â€¢	Uploaded raw CSV data to HDFS and exported a bronze Parquet copy to Google Drive for persistence.
	â€¢	Tools: HDFS, PySpark Core, PySpark SQL

2. Data Preprocessing
	â€¢	Scalable cleaning and normalization using distributed DataFrame operations:
	â€¢	Type casting, trimming, deduplication
	â€¢	Missing-value imputation per genre
	â€¢	Outlier capping (IQR)
	â€¢	Feature scaling (Z-score normalization)
	â€¢	Saved processed silver dataset as Parquet for efficient reuse.

3. Feature Importance Analysis
	â€¢	Used Lasso Regression (L1) and Random Forest Regressor to evaluate predictive features for track popularity.
	â€¢	Found that genre, danceability, and energy are dominant predictors.

4. Composition-Only Popularity Modeling
	â€¢	Applied Ridge Regression using only compositional attributes (tempo, key, duration, etc.).
	â€¢	Confirmed low explanatory power â€” popularity is driven more by perceptual than structural features.

5. Clustering Analysis
	â€¢	Standardized audio features and applied K-Means (k=4), chosen via the elbow method.
	â€¢	Leveraged RDD transformations (map, reduceByKey) for efficient centroid computation.
	â€¢	Identified meaningful clusters representing:
	â€¢	Dance-oriented music
	â€¢	Acoustic/folk tracks
	â€¢	Rap/spoken word
	â€¢	Mainstream pop

â¸»

ğŸ“Š Results
	â€¢	Popularity is largely determined by audio descriptors and categorical attributes.
	â€¢	Random Forest results aligned with correlation analysis.
	â€¢	Clustering revealed coherent genre-based partitions, confirming the value of feature scaling and distributed processing.
	â€¢	End-to-end execution was efficient, reproducible, and fully cloud-based, leveraging Sparkâ€™s DAG optimization and HDFS integration.

â¸»

ğŸš€ How to Run

This project runs entirely in Google Colab â€” no local Spark/Hadoop setup required.

1ï¸âƒ£ Setup

Open Google Colab and upload all notebooks.

2ï¸âƒ£ Mount Google Drive

from google.colab import drive
drive.mount('/content/drive')

3ï¸âƒ£ Prepare the Dataset

Download via KaggleHub or manually place it in your Drive:

data_path = "/content/drive/MyDrive/spotify_dataset.csv"

4ï¸âƒ£ Execute the Pipeline

Run the notebooks in sequence:

Notebook	                              Purpose
01_Data_Ingestion.ipynb	                Configure Hadoop HDFS, ingest dataset, and create bronze Parquet copy
02_Preprocessing.ipynb	                Clean, normalize, and scale data into a silver Parquet dataset
03a_Composition_Popularity_Model.ipynb	Train Ridge Regression on compositional attributes
03b_Popularity_Features.ipynb	          Compute Lasso and Random Forest feature importances
04_Clustering.ipynb	                    Apply K-Means clustering and visualize results

All dependencies install automatically within Colab.

â¸»

ğŸ§  Technologies
	â€¢	Apache Spark (PySpark) â€” distributed computation and MLlib
	â€¢	Hadoop HDFS â€” scalable storage backend
	â€¢	Google Colab + Drive â€” cloud execution and persistence
	â€¢	Python libraries: pandas, numpy, matplotlib, pyspark.ml

â¸»

ğŸ§© Project Structure

â”œâ”€â”€ 01_Data_Ingestion.ipynb
â”œâ”€â”€ 02_Preprocessing.ipynb
â”œâ”€â”€ 03a_Composition_Popularity_Model.ipynb
â”œâ”€â”€ 03b_Popularity_Features.ipynb
â”œâ”€â”€ 04_Clustering.ipynb
â”œâ”€â”€ data/
â”‚   â””â”€â”€ spotify_dataset.csv
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ feature_importance.csv
â”‚   â”œâ”€â”€ clusters_summary.csv
â”‚   â””â”€â”€ visualizations/
â””â”€â”€ README.md
