{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Setup Spark + Drive\n",
        "\n",
        "Sets up PySpark and mounts Google Drive, then loads the bronze Parquet dataset from the ingestion notebook.\n",
        "Initializes a SparkSession for preprocessing and previews the schema and a small sample. The silver path is defined for cleaned/normalized output."
      ],
      "metadata": {
        "id": "QsTUZHIqOFcT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIvGDBIXN-0X",
        "outputId": "f8c3d3b2-0f9b-4ce4-dfad-ac05c89089a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Rows: 114000\n",
            "root\n",
            " |-- Unnamed: 0: integer (nullable = true)\n",
            " |-- track_id: string (nullable = true)\n",
            " |-- artists: string (nullable = true)\n",
            " |-- album_name: string (nullable = true)\n",
            " |-- track_name: string (nullable = true)\n",
            " |-- popularity: string (nullable = true)\n",
            " |-- duration_ms: string (nullable = true)\n",
            " |-- explicit: string (nullable = true)\n",
            " |-- danceability: string (nullable = true)\n",
            " |-- energy: string (nullable = true)\n",
            " |-- key: string (nullable = true)\n",
            " |-- loudness: string (nullable = true)\n",
            " |-- mode: string (nullable = true)\n",
            " |-- speechiness: string (nullable = true)\n",
            " |-- acousticness: string (nullable = true)\n",
            " |-- instrumentalness: double (nullable = true)\n",
            " |-- liveness: string (nullable = true)\n",
            " |-- valence: string (nullable = true)\n",
            " |-- tempo: double (nullable = true)\n",
            " |-- time_signature: double (nullable = true)\n",
            " |-- track_genre: string (nullable = true)\n",
            "\n",
            "+----------+----------------------+----------------------+------------------------------------------------------+--------------------------+----------+-----------+--------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+--------------+-----------+\n",
            "|Unnamed: 0|track_id              |artists               |album_name                                            |track_name                |popularity|duration_ms|explicit|danceability|energy|key|loudness|mode|speechiness|acousticness|instrumentalness|liveness|valence|tempo  |time_signature|track_genre|\n",
            "+----------+----------------------+----------------------+------------------------------------------------------+--------------------------+----------+-----------+--------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+--------------+-----------+\n",
            "|0         |5SuOikwiRyPMVoIQDJUgSV|Gen Hoshino           |Comedy                                                |Comedy                    |73        |230666     |False   |0.676       |0.461 |1  |-6.746  |0   |0.143      |0.0322      |1.01E-6         |0.358   |0.715  |87.917 |4.0           |acoustic   |\n",
            "|1         |4qPNDBW1i3p13qLCt0Ki3A|Ben Woodward          |Ghost (Acoustic)                                      |Ghost - Acoustic          |55        |149610     |False   |0.42        |0.166 |1  |-17.235 |1   |0.0763     |0.924       |5.56E-6         |0.101   |0.267  |77.489 |4.0           |acoustic   |\n",
            "|2         |1iJBSr7s7jYXzM8EGcbK5b|Ingrid Michaelson;ZAYN|To Begin Again                                        |To Begin Again            |57        |210826     |False   |0.438       |0.359 |0  |-9.734  |1   |0.0557     |0.21        |0.0             |0.117   |0.12   |76.332 |4.0           |acoustic   |\n",
            "|3         |6lfxq3CG4xtTiEg7opyCyx|Kina Grannis          |Crazy Rich Asians (Original Motion Picture Soundtrack)|Can't Help Falling In Love|71        |201933     |False   |0.266       |0.0596|0  |-18.515 |1   |0.0363     |0.905       |7.07E-5         |0.132   |0.143  |181.74 |3.0           |acoustic   |\n",
            "|4         |5vjLSffimiIP26QG5WcN2K|Chord Overstreet      |Hold On                                               |Hold On                   |82        |198853     |False   |0.618       |0.443 |2  |-9.681  |1   |0.0526     |0.469       |0.0             |0.0829  |0.167  |119.949|4.0           |acoustic   |\n",
            "+----------+----------------------+----------------------+------------------------------------------------------+--------------------------+----------+-----------+--------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+--------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Install PySpark runtime in Colab\n",
        "!pip -q install pyspark\n",
        "\n",
        "# Mount Google Drive for persistent I/O\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Core Spark imports for transforms and types\n",
        "from pyspark.sql import SparkSession, functions as F, types as T, Window as W\n",
        "\n",
        "# Start a Spark session for preprocessing tasks\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "    .appName(\"SpotifyPreprocessing\")\n",
        "    .getOrCreate()\n",
        ")\n",
        "\n",
        "# Input/Output lakehouse layers\n",
        "BRONZE = \"file:///content/drive/MyDrive/data/spotify/bronze_parquet\"  # from 01_Data_Ingestion.ipynb\n",
        "SILVER = \"file:///content/drive/MyDrive/data/spotify/silver_parquet\"  # target for cleaned data\n",
        "\n",
        "# Load bronze-level Parquet dataset\n",
        "df = spark.read.parquet(BRONZE)\n",
        "\n",
        "print(\"Rows:\", df.count())\n",
        "\n",
        "df.printSchema()\n",
        "\n",
        "df.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Column plan\n",
        "\n",
        "Plans column handling and normalizes types: drops junk columns, trims all strings, converts empty strings to nulls in a single pass, then safely casts booleans and numeric-like fields to proper types.\n",
        "This produces a cleaned silver-ready DataFrame with consistent nulls and dtypes."
      ],
      "metadata": {
        "id": "UGWEyM_ZQJ_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logical column groups for downstream reference/validation\n",
        "id_cols = [\"track_id\"]\n",
        "cat_cols = [\"artists\", \"album_name\", \"track_name\", \"track_genre\", \"key\"]\n",
        "bool_cols = [\"explicit\"]\n",
        "num_cols_as_string = [\n",
        "    \"popularity\",\"duration_ms\",\"danceability\",\"energy\",\"loudness\",\"mode\",\n",
        "    \"speechiness\",\"acousticness\",\"instrumentalness\",\"liveness\",\"valence\",\n",
        "    \"tempo\",\"time_signature\"\n",
        "]\n",
        "drop_cols = [\"Unnamed: 0\"]  # junk index from CSV export\n",
        "\n",
        "# Drop junk columns if present\n",
        "df1 = df.drop(*[c for c in drop_cols if c in df.columns])\n",
        "\n",
        "# Detect string columns programmatically to avoid hard-coding\n",
        "string_cols = [f.name for f in df1.schema.fields if isinstance(f.dataType, T.StringType)]\n",
        "\n",
        "# Trim whitespace in all string cols and normalize \"\" -> null\n",
        "exprs = []\n",
        "for c in df1.columns:\n",
        "    if c in string_cols:\n",
        "        trimmed = F.trim(F.col(c))\n",
        "        exprs.append(F.when(trimmed == \"\", None).otherwise(trimmed).alias(c))\n",
        "    else:\n",
        "        exprs.append(F.col(c))\n",
        "df1 = df1.select(*exprs)\n",
        "\n",
        "# Cast with null-on-failure semantics\n",
        "def safe_cast(col, new_type):\n",
        "    casted = F.col(col).cast(new_type)\n",
        "    return F.when(casted.isNotNull(), casted).otherwise(None)\n",
        "\n",
        "# Begin type normalization on a working DataFrame\n",
        "df2 = df1\n",
        "\n",
        "# Robust explicit → boolean mapping from common truthy/falsey strings\n",
        "if \"explicit\" in df2.columns:\n",
        "    df2 = df2.withColumn(\n",
        "        \"explicit\",\n",
        "        F.when(F.lower(F.col(\"explicit\")).isin(\"true\",\"1\",\"t\",\"yes\"), F.lit(True))\n",
        "         .when(F.lower(F.col(\"explicit\")).isin(\"false\",\"0\",\"f\",\"no\"), F.lit(False))\n",
        "         .otherwise(None)  # unrecognized values -> null\n",
        "         .cast(T.BooleanType())\n",
        "    )\n",
        "\n",
        "# Cast numeric-looking columns safely to their intended types\n",
        "for c in num_cols_as_string:\n",
        "    if c in df2.columns:\n",
        "        if c in [\"popularity\", \"duration_ms\", \"mode\", \"time_signature\"]:\n",
        "            df2 = df2.withColumn(c, safe_cast(c, T.IntegerType()))\n",
        "        else:\n",
        "            df2 = df2.withColumn(c, safe_cast(c, T.DoubleType()))\n",
        "\n",
        "# 'key' is typically an integer musical key index; cast if currently string\n",
        "if \"key\" in df2.columns and dict(df2.dtypes).get(\"key\") == \"string\":\n",
        "    df2 = df2.withColumn(\"key\", safe_cast(\"key\", T.IntegerType()))\n",
        "\n",
        "df2.printSchema()\n",
        "df2.show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zv5Zi6IQMTA",
        "outputId": "a5d22072-a3a8-4ccd-dc39-56d734a99931"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- track_id: string (nullable = true)\n",
            " |-- artists: string (nullable = true)\n",
            " |-- album_name: string (nullable = true)\n",
            " |-- track_name: string (nullable = true)\n",
            " |-- popularity: integer (nullable = true)\n",
            " |-- duration_ms: integer (nullable = true)\n",
            " |-- explicit: boolean (nullable = true)\n",
            " |-- danceability: double (nullable = true)\n",
            " |-- energy: double (nullable = true)\n",
            " |-- key: integer (nullable = true)\n",
            " |-- loudness: double (nullable = true)\n",
            " |-- mode: integer (nullable = true)\n",
            " |-- speechiness: double (nullable = true)\n",
            " |-- acousticness: double (nullable = true)\n",
            " |-- instrumentalness: double (nullable = true)\n",
            " |-- liveness: double (nullable = true)\n",
            " |-- valence: double (nullable = true)\n",
            " |-- tempo: double (nullable = true)\n",
            " |-- time_signature: integer (nullable = true)\n",
            " |-- track_genre: string (nullable = true)\n",
            "\n",
            "+----------------------+----------------------+------------------------------------------------------+--------------------------+----------+-----------+--------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+--------------+-----------+\n",
            "|track_id              |artists               |album_name                                            |track_name                |popularity|duration_ms|explicit|danceability|energy|key|loudness|mode|speechiness|acousticness|instrumentalness|liveness|valence|tempo  |time_signature|track_genre|\n",
            "+----------------------+----------------------+------------------------------------------------------+--------------------------+----------+-----------+--------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+--------------+-----------+\n",
            "|5SuOikwiRyPMVoIQDJUgSV|Gen Hoshino           |Comedy                                                |Comedy                    |73        |230666     |false   |0.676       |0.461 |1  |-6.746  |0   |0.143      |0.0322      |1.01E-6         |0.358   |0.715  |87.917 |4             |acoustic   |\n",
            "|4qPNDBW1i3p13qLCt0Ki3A|Ben Woodward          |Ghost (Acoustic)                                      |Ghost - Acoustic          |55        |149610     |false   |0.42        |0.166 |1  |-17.235 |1   |0.0763     |0.924       |5.56E-6         |0.101   |0.267  |77.489 |4             |acoustic   |\n",
            "|1iJBSr7s7jYXzM8EGcbK5b|Ingrid Michaelson;ZAYN|To Begin Again                                        |To Begin Again            |57        |210826     |false   |0.438       |0.359 |0  |-9.734  |1   |0.0557     |0.21        |0.0             |0.117   |0.12   |76.332 |4             |acoustic   |\n",
            "|6lfxq3CG4xtTiEg7opyCyx|Kina Grannis          |Crazy Rich Asians (Original Motion Picture Soundtrack)|Can't Help Falling In Love|71        |201933     |false   |0.266       |0.0596|0  |-18.515 |1   |0.0363     |0.905       |7.07E-5         |0.132   |0.143  |181.74 |3             |acoustic   |\n",
            "|5vjLSffimiIP26QG5WcN2K|Chord Overstreet      |Hold On                                               |Hold On                   |82        |198853     |false   |0.618       |0.443 |2  |-9.681  |1   |0.0526     |0.469       |0.0             |0.0829  |0.167  |119.949|4             |acoustic   |\n",
            "+----------------------+----------------------+------------------------------------------------------+--------------------------+----------+-----------+--------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+--------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3)  De-duplication & basic filters\n",
        "\n",
        "De-duplicates records and applies minimal quality filters.\n",
        "Keeps one row per (track_id, album_name, track_name) using popularity (then duration) to choose the winner; warns if key columns are missing, drops rows without essential IDs/genre, and filters out non-positive durations."
      ],
      "metadata": {
        "id": "nOSgxJmWQSl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cache to avoid re-computation when counting before/after\n",
        "df2 = df2.cache()\n",
        "before = df2.count()  # triggers evaluation\n",
        "\n",
        "# Keep the \"best\" row by popularity, then duration\n",
        "keys = [\"track_id\", \"album_name\", \"track_name\"]\n",
        "existing_keys = [k for k in keys if k in df2.columns]\n",
        "if existing_keys:\n",
        "    w = W.partitionBy(*existing_keys).orderBy(\n",
        "        F.col(\"popularity\").desc_nulls_last(),\n",
        "        F.col(\"duration_ms\").desc_nulls_last()\n",
        "    )\n",
        "    df3 = (\n",
        "        df2.withColumn(\"_rn\", F.row_number().over(w))\n",
        "           .where(F.col(\"_rn\") == 1)  # keep top-ranked per key\n",
        "           .drop(\"_rn\")\n",
        "    )\n",
        "else:\n",
        "    # Fallback: if keys are missing, remove full-row duplicates\n",
        "    df3 = df2.dropDuplicates()\n",
        "\n",
        "after = df3.count()\n",
        "print(\"Dropped duplicates:\", before - after)\n",
        "\n",
        "# Ensure essential identifiers/genre are present\n",
        "required = [c for c in [\"track_id\", \"track_name\", \"track_genre\"] if c in df3.columns]\n",
        "if len(required) < 3:\n",
        "    missing = set([\"track_id\", \"track_name\", \"track_genre\"]) - set(required)\n",
        "    print(f\"Warning: missing expected columns: {sorted(missing)}\")\n",
        "\n",
        "if required:\n",
        "    df3 = df3.where(\n",
        "        F.col(\"track_id\").isNotNull()\n",
        "        & F.col(\"track_name\").isNotNull()\n",
        "        & F.col(\"track_genre\").isNotNull()\n",
        "    )\n",
        "\n",
        "# Sanity check: drop rows with non-positive durations when available\n",
        "if \"duration_ms\" in df3.columns:\n",
        "    df3 = df3.where((F.col(\"duration_ms\").isNull()) | (F.col(\"duration_ms\") > 0))\n",
        "\n",
        "# Remove rows where track_genre looks numeric\n",
        "numeric_pattern = r\"^[+-]?\\d+(\\.\\d+)?([eE][+-]?\\d+)?$\"\n",
        "df3 = df3.filter(~F.col(\"track_genre\").rlike(numeric_pattern))\n",
        "\n",
        "df3.select(\"track_genre\").distinct().show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UP0l2q8LQWAG",
        "outputId": "5706b760-b1e2-43b5-d7a6-f234c155ba68"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropped duplicates: 24259\n",
            "+-----------------+\n",
            "|track_genre      |\n",
            "+-----------------+\n",
            "|anime            |\n",
            "|singer-songwriter|\n",
            "|folk             |\n",
            "|hardstyle        |\n",
            "|pop              |\n",
            "|alternative      |\n",
            "|death-metal      |\n",
            "|idm              |\n",
            "|detroit-techno   |\n",
            "|k-pop            |\n",
            "|j-dance          |\n",
            "|ambient          |\n",
            "|guitar           |\n",
            "|goth             |\n",
            "|cantopop         |\n",
            "|blues            |\n",
            "|study            |\n",
            "|malay            |\n",
            "|dance            |\n",
            "|breakbeat        |\n",
            "+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Missing values — median imputation per genre\n",
        "\n",
        "Imputes missing numeric values using per-genre medians, with global medians as a fallback."
      ],
      "metadata": {
        "id": "LcW4oQ3-QaZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Target numeric-like columns to impute if present in the DataFrame\n",
        "target_num_cols = [\n",
        "    \"popularity\",\"duration_ms\",\"danceability\",\"energy\",\"loudness\",\"mode\",\n",
        "    \"speechiness\",\"acousticness\",\"instrumentalness\",\"liveness\",\"valence\",\n",
        "    \"tempo\",\"time_signature\",\"key\"\n",
        "]\n",
        "target_num_cols = [c for c in target_num_cols if c in df3.columns]\n",
        "\n",
        "# If we lack genre or there are no numeric targets, fall back to global medians\n",
        "if \"track_genre\" not in df3.columns or not target_num_cols:\n",
        "    print(\"Note: track_genre not found or no numeric columns; using global medians only.\")\n",
        "\n",
        "    # Compute global medians for distributed efficiency\n",
        "    global_row = df3.select(\n",
        "        *[F.expr(f\"percentile_approx({c}, 0.5)\").alias(f\"med_{c}\") for c in target_num_cols]\n",
        "    ).first()\n",
        "\n",
        "    # Convert Row to a simple dict of column -> float/None\n",
        "    global_vals = {\n",
        "        c: float(global_row[f\"med_{c}\"]) if global_row[f\"med_{c}\"] is not None else None\n",
        "        for c in target_num_cols\n",
        "    }\n",
        "\n",
        "    # Impute using global medians only\n",
        "    df4 = df3\n",
        "    for c in target_num_cols:\n",
        "        df4 = df4.withColumn(c, F.coalesce(F.col(c), F.lit(global_vals[c])))\n",
        "\n",
        "else:\n",
        "    # Compute per-genre medians for all target columns\n",
        "    per_genre = (\n",
        "        df3.groupBy(\"track_genre\")\n",
        "           .agg(*[F.expr(f\"percentile_approx({c}, 0.5)\").alias(f\"med_{c}\") for c in target_num_cols])\n",
        "           .cache()\n",
        "    )\n",
        "\n",
        "    # Also compute global medians when genre medians are null\n",
        "    global_row = df3.select(\n",
        "        *[F.expr(f\"percentile_approx({c}, 0.5)\").alias(f\"med_{c}\") for c in target_num_cols]\n",
        "    ).first()\n",
        "    global_vals = {\n",
        "        f\"med_{c}\": (float(global_row[f\"med_{c}\"]) if global_row[f\"med_{c}\"] is not None else None)\n",
        "        for c in target_num_cols\n",
        "    }\n",
        "\n",
        "    # Attach per-genre median columns to each row\n",
        "    df4 = df3.join(per_genre, on=\"track_genre\", how=\"left\")\n",
        "\n",
        "    # For each target column: value <- value or genre median or global median\n",
        "    for c in target_num_cols:\n",
        "        med_col = f\"med_{c}\"\n",
        "        df4 = df4.withColumn(\n",
        "            c,\n",
        "            F.coalesce(F.col(c), F.col(med_col), F.lit(global_vals[med_col]))\n",
        "        )\n",
        "\n",
        "    # Clean up helper columns\n",
        "    df4 = df4.drop(*[f\"med_{c}\" for c in target_num_cols])\n",
        "\n",
        "df4.select(\"track_genre\", *[c for c in target_num_cols[:6]]).show(5, truncate=False)"
      ],
      "metadata": {
        "id": "sHCJMcl3QdWJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "973beeb1-c20a-487d-9b8b-cb21dae28ec3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----------+-----------+------------+------+--------+----+\n",
            "|track_genre   |popularity|duration_ms|danceability|energy|loudness|mode|\n",
            "+--------------+----------+-----------+------------+------+--------+----+\n",
            "|hip-hop       |62.0      |190203.0   |0.679       |0.77  |-3.537  |1.0 |\n",
            "|minimal-techno|19.0      |331240.0   |0.519       |0.431 |-13.606 |0.0 |\n",
            "|comedy        |24.0      |127040.0   |0.536       |0.78  |-9.449  |0.0 |\n",
            "|chill         |0.0       |176320.0   |0.613       |0.471 |-6.644  |0.0 |\n",
            "|punk-rock     |38.0      |177266.0   |0.554       |0.921 |-4.589  |1.0 |\n",
            "+--------------+----------+-----------+------------+------+--------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Outliers — IQR capping per genre\n",
        "\n",
        "Caps numeric outliers per genre using the IQR rule, then applies domain-aware clamps.\n",
        "Skips categorical-like integers and safely handles null stats."
      ],
      "metadata": {
        "id": "b6ZwtyGOQkqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Columns eligible for IQR capping\n",
        "cap_cols = [c for c in target_num_cols if c not in [\"mode\", \"key\", \"time_signature\"]]\n",
        "\n",
        "# If we can't segment by genre or nothing to cap, pass-through\n",
        "if \"track_genre\" not in df4.columns or not cap_cols:\n",
        "    df5 = df4\n",
        "else:\n",
        "    # Compute per-genre quartiles for each target column\n",
        "    q1_exprs = [F.expr(f\"percentile_approx({c}, 0.25)\").alias(f\"q1_{c}\") for c in cap_cols]\n",
        "    q3_exprs = [F.expr(f\"percentile_approx({c}, 0.75)\").alias(f\"q3_{c}\") for c in cap_cols]\n",
        "    iqr_stats = df4.groupBy(\"track_genre\").agg(*q1_exprs, *q3_exprs).cache()\n",
        "\n",
        "    # Attach per-genre Q1/Q3 to each row\n",
        "    df5 = df4.join(iqr_stats, on=\"track_genre\", how=\"left\")\n",
        "\n",
        "    # Apply IQR capping per column; leave as-is when value or bounds are null\n",
        "    for c in cap_cols:\n",
        "        q1c, q3c = F.col(f\"q1_{c}\"), F.col(f\"q3_{c}\")\n",
        "        iqr = (q3c - q1c)\n",
        "        low = q1c - F.lit(1.5) * iqr\n",
        "        high = q3c + F.lit(1.5) * iqr\n",
        "\n",
        "        capped = (\n",
        "            F.when(F.col(c).isNull() | q1c.isNull() | q3c.isNull(), F.col(c))\n",
        "             .when(F.col(c) < low, low)\n",
        "             .when(F.col(c) > high, high)\n",
        "             .otherwise(F.col(c))\n",
        "        )\n",
        "        df5 = df5.withColumn(c, capped)\n",
        "\n",
        "    # Domain-aware clamps after IQR capping:\n",
        "    #  - bounded rates should fall within [0, 1]\n",
        "    for c in set(cap_cols).intersection({\n",
        "        \"danceability\",\"energy\",\"speechiness\",\"acousticness\",\n",
        "        \"instrumentalness\",\"liveness\",\"valence\"\n",
        "    }):\n",
        "        df5 = df5.withColumn(\n",
        "            c,\n",
        "            F.when(F.col(c).isNull(), None)\n",
        "             .when(F.col(c) < 0, F.lit(0.0))\n",
        "             .when(F.col(c) > 1, F.lit(1.0))\n",
        "             .otherwise(F.col(c))\n",
        "        )\n",
        "\n",
        "    #  - duration must be non-negative\n",
        "    if \"duration_ms\" in df5.columns:\n",
        "        df5 = df5.withColumn(\n",
        "            \"duration_ms\",\n",
        "            F.when(F.col(\"duration_ms\").isNull(), None)\n",
        "             .when(F.col(\"duration_ms\") < 0, F.lit(0))\n",
        "             .otherwise(F.col(\"duration_ms\"))\n",
        "        )\n",
        "\n",
        "    #  - popularity constrained to [0, 100]\n",
        "    if \"popularity\" in df5.columns:\n",
        "        df5 = df5.withColumn(\n",
        "            \"popularity\",\n",
        "            F.when(F.col(\"popularity\").isNull(), None)\n",
        "             .when(F.col(\"popularity\") < 0, F.lit(0))\n",
        "             .when(F.col(\"popularity\") > 100, F.lit(100))\n",
        "             .otherwise(F.col(\"popularity\"))\n",
        "        )\n",
        "\n",
        "    # Drop helper quartile columns added during the join\n",
        "    helper_cols = [f\"q1_{c}\" for c in cap_cols] + [f\"q3_{c}\" for c in cap_cols]\n",
        "    df5 = df5.drop(*[h for h in helper_cols if h in df5.columns])\n",
        "\n",
        "df5.select(\"track_genre\", *[c for c in cap_cols[:6] if c in df5.columns]).show(5, truncate=False)"
      ],
      "metadata": {
        "id": "BCOyDzpAQn2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c022df8-3d7f-497a-c5be-3bf2b210e879"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----------+-----------+------------+------+--------+-----------+\n",
            "|track_genre   |popularity|duration_ms|danceability|energy|loudness|speechiness|\n",
            "+--------------+----------+-----------+------------+------+--------+-----------+\n",
            "|hip-hop       |62.0      |190203.0   |0.679       |0.77  |-3.537  |0.19       |\n",
            "|minimal-techno|19.0      |331240.0   |0.519       |0.431 |-13.606 |0.0291     |\n",
            "|comedy        |24.0      |127040.0   |0.536       |0.78  |-9.449  |0.945      |\n",
            "|chill         |36.0      |176320.0   |0.613       |0.471 |-6.644  |0.107      |\n",
            "|punk-rock     |38.0      |177266.0   |0.554       |0.921 |-4.589  |0.0758     |\n",
            "+--------------+----------+-----------+------------+------+--------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) Normalization — Z-score for numerics\n",
        "\n",
        "Standardizes continuous features with global Z-scores.\n",
        "Skips discrete/categorical-like integers and only normalizes when stats are valid."
      ],
      "metadata": {
        "id": "hmDulC1VQtGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Continuous columns only; exclude categorical-like integer fields\n",
        "cont_cols = [\n",
        "    c for c in target_num_cols\n",
        "    if c in df5.columns and c not in [\"mode\", \"time_signature\", \"key\"]\n",
        "]\n",
        "\n",
        "# Compute global means and population stddevs for all targets\n",
        "agg_exprs = []\n",
        "for c in cont_cols:\n",
        "    agg_exprs.append(F.mean(c).alias(f\"mean_{c}\"))\n",
        "    agg_exprs.append(F.stddev_pop(c).alias(f\"std_{c}\"))  # population stddev\n",
        "\n",
        "stats_row = df5.agg(*agg_exprs).first()\n",
        "stats = stats_row.asDict()\n",
        "\n",
        "df6 = df5\n",
        "\n",
        "# Add {col}_z only when mean/std are defined and std != 0\n",
        "for c in cont_cols:\n",
        "    mean_c = stats.get(f\"mean_{c}\")\n",
        "    std_c  = stats.get(f\"std_{c}\")\n",
        "    if mean_c is not None and std_c not in (None, 0.0):\n",
        "        df6 = df6.withColumn(\n",
        "            f\"{c}_z\",\n",
        "            (F.col(c) - F.lit(float(mean_c))) / F.lit(float(std_c))\n",
        "        )\n",
        "\n",
        "df6.select(\n",
        "    *(id_cols + [\"track_name\", \"track_genre\"] + cont_cols + [f\"{c}_z\" for c in cont_cols])\n",
        ").show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfixa8UcQwBd",
        "outputId": "aba5a9e8-ae51-4993-e27c-6e0c3bb32dbe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------+----------------------------------------+--------------+----------+-----------+------------+------+--------+-----------+------------+---------------------+--------+-------+-------+-------------------+--------------------+---------------------+-------------------+--------------------+--------------------+---------------------+--------------------+-------------------+--------------------+------------------+\n",
            "|track_id              |track_name                              |track_genre   |popularity|duration_ms|danceability|energy|loudness|speechiness|acousticness|instrumentalness     |liveness|valence|tempo  |popularity_z       |duration_ms_z       |danceability_z       |energy_z           |loudness_z          |speechiness_z       |acousticness_z       |instrumentalness_z  |liveness_z         |valence_z           |tempo_z           |\n",
            "+----------------------+----------------------------------------+--------------+----------+-----------+------------+------+--------+-----------+------------+---------------------+--------+-------+-------+-------------------+--------------------+---------------------+-------------------+--------------------+--------------------+---------------------+--------------------+-------------------+--------------------+------------------+\n",
            "|000RDCYioLteXcutOjeweY|Teeje Week                              |hip-hop       |62.0      |190203.0   |0.679       |0.77  |-3.537  |0.19       |0.0583      |0.0                  |0.0825  |0.839  |161.721|1.4549955461167612 |-0.42404907723317764|0.6606975471506404   |0.5243936704310442 |0.9616381456824863  |1.0864481758596305  |-0.7876255720849905  |-0.48542377685196325|-0.7240519257922824|1.409178047742767   |1.3350655502649542|\n",
            "|000qpdoc97IMTBvF8gwcpy|Tief                                    |minimal-techno|19.0      |331240.0   |0.519       |0.431 |-13.606 |0.0291     |9.64E-4     |0.72                 |0.0916  |0.234  |129.971|-0.7030493463894383|1.2936223424429194  |-0.24793563845183958 |-0.8020172437959793|-1.0211176661147876 |-0.5030545687913841 |-0.9581073195503755  |1.8605606102236751  |-0.6696430030771994|-0.8956768652207994 |0.2667689031615721|\n",
            "|0017XiMkqbTfF2AUOzlhj6|Thanksgiving Chicken                    |comedy        |24.0      |127040.0   |0.536       |0.78  |-9.449  |0.945      |0.792       |0.0                  |0.735   |0.452  |173.912|-0.4521138937724384|-1.1933031019288343 |-0.151393362481576   |0.563520836042461  |-0.20253430037427042|8.544960122481855   |1.3939437406566197   |-0.48542377685196325|3.177247202954061  |-0.06516716104549777|1.7452578156141616|\n",
            "|001APMDOl3qtx1526T11n1|Better                                  |chill         |36.0      |176320.0   |0.613       |0.471 |-6.644  |0.107      |0.316       |1.37E-6              |0.117   |0.406  |143.064|0.15013119250836152|-0.593128342386033  |0.28588635808961715  |-0.6455085813503129|0.3498174775670696  |0.2665058029197037  |-0.021385403223721764|-0.4854193129650045 |-0.5177763396746596|-0.24041232798157053|0.7073108874300625|\n",
            "|001YQlnDSduXd5LgBd66gT|El Tiempo Es Dinero - Remasterizado 2007|punk-rock     |38.0      |177266.0   |0.554       |0.921 |-4.589  |0.0758     |0.0194      |0.0016524999999999999|0.329   |0.7    |183.571|0.2505053735551615 |-0.5816071304840953 |-0.049172129101296945|1.1152138711634354 |0.7544816143476235  |-0.04171349871554576|-0.9032900756500017  |-0.48003941685245977|0.7497721895118917 |0.8796328693924598  |2.0702555263030296|\n",
            "+----------------------+----------------------------------------+--------------+----------+-----------+------------+------+--------+-----------+------------+---------------------+--------+-------+-------+-------------------+--------------------+---------------------+-------------------+--------------------+--------------------+---------------------+--------------------+-------------------+--------------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7) Save silver dataset to Drive (Parquet)\n",
        "\n",
        "Saves the fully cleaned and normalized silver-level dataset to Google Drive in Parquet format.\n",
        "The silver layer represents standardized, deduplicated, and imputed data ready for analytics or modeling."
      ],
      "metadata": {
        "id": "Zzc1dvBQQ5pW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Persist the preprocessed DataFrame as Parquet (overwrite existing version)\n",
        "df6.write.mode(\"overwrite\").parquet(SILVER)\n",
        "\n",
        "# Reload the written dataset to confirm successful save\n",
        "df_silver = spark.read.parquet(SILVER)\n",
        "\n",
        "print(\"Silver rows:\", df_silver.count())\n",
        "df_silver.printSchema()\n",
        "\n",
        "df_silver.show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pB0kXn-9Q6wL",
        "outputId": "ff2e1beb-ce13-4a7a-e8c7-a01b547b85dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silver rows: 89620\n",
            "root\n",
            " |-- track_genre: string (nullable = true)\n",
            " |-- track_id: string (nullable = true)\n",
            " |-- artists: string (nullable = true)\n",
            " |-- album_name: string (nullable = true)\n",
            " |-- track_name: string (nullable = true)\n",
            " |-- popularity: double (nullable = true)\n",
            " |-- duration_ms: double (nullable = true)\n",
            " |-- explicit: boolean (nullable = true)\n",
            " |-- danceability: double (nullable = true)\n",
            " |-- energy: double (nullable = true)\n",
            " |-- key: double (nullable = true)\n",
            " |-- loudness: double (nullable = true)\n",
            " |-- mode: double (nullable = true)\n",
            " |-- speechiness: double (nullable = true)\n",
            " |-- acousticness: double (nullable = true)\n",
            " |-- instrumentalness: double (nullable = true)\n",
            " |-- liveness: double (nullable = true)\n",
            " |-- valence: double (nullable = true)\n",
            " |-- tempo: double (nullable = true)\n",
            " |-- time_signature: double (nullable = true)\n",
            " |-- popularity_z: double (nullable = true)\n",
            " |-- duration_ms_z: double (nullable = true)\n",
            " |-- danceability_z: double (nullable = true)\n",
            " |-- energy_z: double (nullable = true)\n",
            " |-- loudness_z: double (nullable = true)\n",
            " |-- speechiness_z: double (nullable = true)\n",
            " |-- acousticness_z: double (nullable = true)\n",
            " |-- instrumentalness_z: double (nullable = true)\n",
            " |-- liveness_z: double (nullable = true)\n",
            " |-- valence_z: double (nullable = true)\n",
            " |-- tempo_z: double (nullable = true)\n",
            "\n",
            "+--------------+----------------------+------------------------+---------------------------+--------------------------------------------------+----------+-----------+--------+------------+------+---+--------+----+-------------------+------------+---------------------+-------------------+-------+-------+--------------+-------------------+-------------------+---------------------+-------------------+--------------------+--------------------+-------------------+--------------------+-------------------+--------------------+-------------------+\n",
            "|track_genre   |track_id              |artists                 |album_name                 |track_name                                        |popularity|duration_ms|explicit|danceability|energy|key|loudness|mode|speechiness        |acousticness|instrumentalness     |liveness           |valence|tempo  |time_signature|popularity_z       |duration_ms_z      |danceability_z       |energy_z           |loudness_z          |speechiness_z       |acousticness_z     |instrumentalness_z  |liveness_z         |valence_z           |tempo_z            |\n",
            "+--------------+----------------------+------------------------+---------------------------+--------------------------------------------------+----------+-----------+--------+------------+------+---+--------+----+-------------------+------------+---------------------+-------------------+-------+-------+--------------+-------------------+-------------------+---------------------+-------------------+--------------------+--------------------+-------------------+--------------------+-------------------+--------------------+-------------------+\n",
            "|german        |0000vdREvCVMxbQTkS888c|Rill                    |Lolly                      |Lolly                                             |44.0      |160725.0   |true    |0.91        |0.374 |8.0|-9.844  |0.0 |0.199              |0.0757      |0.00301              |0.154              |0.432  |104.042|4.0           |0.5516279166955614 |-0.7830578345749531|1.9725367088642205   |-1.025042087781054 |-0.28031645805228433|1.1753575897928756  |-0.7358887504389445|-0.47561625878932756|-0.2965532473166295|-0.14136071188726862|-0.6056677507831081|\n",
            "|club          |000CC8EParg64OmTxVnZ0p|Glee Cast               |Glee Love Songs            |It's All Coming Back To Me Now (Glee Cast Version)|47.0      |322933.0   |false   |0.269       |0.516 |0.0|-7.361  |1.0 |0.0366             |0.406       |0.0                  |0.117              |0.341  |178.174|4.0           |0.7021891882657614 |1.1924524616084622 |-1.6676749909557143  |-0.4694363360989379|0.20862809261735815 |-0.42896339051367993|0.24621884666962016|-0.48542377685196325|-0.5177763396746596|-0.4880413682173256 |1.8886619198647006 |\n",
            "|minimal-techno|000Iz0K615UepwSJ5z2RE5|Paul Kalkbrenner;Pig&Dan|X                          |Böxig Leise - Pig & Dan Remix                     |22.0      |515360.0   |false   |0.686       |0.56  |5.0|-13.264 |0.0 |0.0462             |0.00114     |0.4699999999999999   |0.111              |0.108  |119.997|4.0           |-0.5524880748192383|3.535996058494473  |0.7004502490207489   |-0.2972768074087046|-0.953772101745469  |-0.3341266823182185 |-0.9575840045728065|1.0459826980446338  |-0.5536503546516376|-1.3756962355239555 |-0.0688276561521015|\n",
            "|happy         |002qpSULhHAw6DGqFxbaO1|Tokyo Ghetto Pussy      |Disco 2001                 |Love Generation                                   |17.0      |410666.0   |false   |0.531       |0.95  |9.0|-9.744  |0.0 |0.0433             |0.00122     |0.826                |0.0613             |0.553  |159.974|4.0           |-0.8034235274362383|2.26094134511026   |-0.17978814953165353 |1.2286826514365432 |-0.2606247725641796 |-0.36277527125226416|-0.9573461341284567|2.2059416449875884  |-0.8508067787109376|0.31961027070544484 |1.2762839993203992 |\n",
            "|idm           |003lo4y8gOylAqDs2scLx2|Dither                  |Dominator - We Will Prevail|Addiction                                         |21.0      |177166.0   |true    |0.553       |0.978 |8.0|-0.647  |1.0 |0.12100000000000001|0.081       |0.0030000000000001137|0.31379999999999997|0.306  |180.055|4.0           |-0.6026751653426383|-0.5828250175773233|-0.054851086511312444|1.3382387151485098 |1.5307278562887154  |0.40480933570475175 |-0.720129833500781 |-0.47564884190581436|0.6588913515702143 |-0.6213800821904246 |1.9519521873671088 |\n",
            "+--------------+----------------------+------------------------+---------------------------+--------------------------------------------------+----------+-----------+--------+------------+------+---+--------+----+-------------------+------------+---------------------+-------------------+-------+-------+--------------+-------------------+-------------------+---------------------+-------------------+--------------------+--------------------+-------------------+--------------------+-------------------+--------------------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}